{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend Word2Vec Model with Phonemes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word2Vec model trained with 100B words\n",
    "\n",
    "\n",
    "from https://code.google.com/archive/p/word2vec/ \n",
    "### and wrap-it up in a ready-to-use class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None # cache of Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def set_logging_as(a_level):\n",
    "    logger.setLevel(a_level)\n",
    "\n",
    "    # logging.basicConfig(format='%(asctime)s : %(levelname)s : %(module)s:%(lineno)d : %(funcName)s(%(threadName)s) : %(message)s')\n",
    "\n",
    "#     ,\n",
    "#         level=a_level)\n",
    "\n",
    "# initialization: \n",
    "set_logging_as(logging.DEBUG)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.getLevelName(logger.getEffectiveLevel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_logging_as(logging.DEBUG)\n",
    "logger.info(\"lalala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_logging_as(logging.CRITICAL)\n",
    "logger.info(\"lalala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create logger\n",
    "alogger = logging.getLogger(__name__)\n",
    "alogger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "# add ch to logger\n",
    "alogger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logging.getLevelName(alogger.getEffectiveLevel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alogger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alogger.info(\"lala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim \n",
    "import bisect \n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "class ModelWrapper():\n",
    "        \n",
    "    default_shelf_filename = 'shelf_from0_for2999999.shelf'\n",
    "        \n",
    "    def __init__(self, m, sounds_dict = None):\n",
    "        if m is None:\n",
    "            print(\"Loading model...\")\n",
    "            self.model = gensim.models.word2vec.KeyedVectors.load_word2vec_format('{}/GoogleNews-vectors-negative300.bin.gz'.format(data_dir), binary=True)\n",
    "            print(\"Model succesfully loaded\")\n",
    "        else:\n",
    "            print(\"[init] Model provided. If you want me to FORCE re-load it, call ModelWrapper's constructor with 'None'\")\n",
    "            self.model = m            \n",
    "        # sort all the words in the model, so that we can auto-complete queries quickly\n",
    "        print(\"Sort all the words in the model, so that we can auto-complete queries quickly...\")\n",
    "        self.orig_words = [gensim.utils.to_unicode(word) for word in self.model.index2word]\n",
    "        indices = [i for i, _ in sorted(enumerate(self.orig_words), key=lambda item: item[1].lower())]\n",
    "        self.all_words = [self.orig_words[i].lower() for i in indices]  # lowercased, sorted as lowercased\n",
    "        self.orig_words = [self.orig_words[i] for i in indices]  # original letter casing, but sorted as if lowercased\n",
    "        \n",
    "        # sounds dictionary \n",
    "        if sounds_dict is None:\n",
    "            print(\"Loading default sounds dictionary from '{}'...\".format(self.default_shelf_filename))\n",
    "            self.sounds_dict = shelve.open(self.default_shelf_filename, flag='r')  \n",
    "            print(\"Sounds dictionary succesfully loaded\")\n",
    "        else:\n",
    "            self.sounds_dict = sounds_dict\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "    def suggest(self, term):\n",
    "        \"\"\"\n",
    "        For a given prefix, return 10 words that exist in the model start start with that prefix\n",
    "        \"\"\"\n",
    "        prefix = gensim.utils.to_unicode(term).strip().lower()\n",
    "        count = 10\n",
    "        pos = bisect.bisect_left(self.all_words, prefix)\n",
    "        result = self.orig_words[pos: pos + count]\n",
    "        logger.info(\"suggested %r: %s\" % (prefix, result))\n",
    "        return result      \n",
    "    \n",
    "    def most_similar(self, positive, negative):\n",
    "        \"\"\"\n",
    "            positive: an array of positive words\n",
    "            negative: an array of negative words \n",
    "        \"\"\"                \n",
    "        try:\n",
    "            result = self.model.most_similar(\n",
    "                positive=[word.strip() for word in positive if word],\n",
    "                negative=[word.strip() for word in negative if word],\n",
    "                topn=5)\n",
    "        except:\n",
    "            result = []\n",
    "        logger.info(\"similars for %s vs. %s: %s\" % (positive, negative, result))\n",
    "        return {'similars': result}    \n",
    "    \n",
    "    def vec_repr(self, word):\n",
    "        \"\"\"\n",
    "            If 'word' belongs in the vocabulary, returns its \n",
    "            word2vec representation. Otherwise returns a vector of 0's\n",
    "            of the same length of the other words. \n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.model.word_vec(word)\n",
    "        except KeyError:\n",
    "            logger.debug(\"'{}' not in Model. Returning [0]'s vector.\".format(word))\n",
    "            return np.zeros(self.model.vector_size)\n",
    "        \n",
    "    def sound_to_word(self, a_sound: str) -> str:\n",
    "        return self.sounds_dict[a_sound]\n",
    "    # self.sound_repr(a_sound)[\"word\"]\n",
    "\n",
    "    def sound_to_vec(self, a_sound: str) -> str:\n",
    "        return self.vec_repr(self.sound_to_word(a_sound))\n",
    "\n",
    "    def sound_repr(self, a_sound: str) -> Dict:\n",
    "        # w = self.sounds_dict[a_sound]\n",
    "        return {'word': self.sound_to_word(a_sound), 'vec': self.sound_to_vec(a_sound)}  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mw = ModelWrapper(model)\n",
    "model = mw.model # just cache in case I re-call this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 67810\n",
    "print(key_list[idx])\n",
    "mw.sound_to_word(key_list[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "key_list = list(mw.sounds_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = 6780\n",
    "print(\"'{}' is the sound of '{}'\".format(key_list[idx], mw.sounds_dict[key_list[idx]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mw.sounds_dict[\"ju:\"]\n",
    "mw.sound_to_word(\"ju:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mw.model.syn0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type(mw.model.vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# my_dictionary = {k: f(v) for k, v in my_dictionary.items()}\n",
    "mw.model.index2word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mw.model['skill']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def build_phonemes_dict(from_idx, how_many_words):\n",
    "#     sent = ' '.join(mw.model.index2word[from_idx:from_idx + how_many_words])\n",
    "#     print(sent)\n",
    "#     array_phonemes =  graphs2phones(sent)\n",
    "#     print(array_phonemes)\n",
    "#     assert len(array_phonemes) == how_many_words, \"(Have {} phoneme-strings, {} words) Looks like some words in vocab have phonemes-strings > 1\".format(len(array_phonemes), how_many_words)\n",
    "#     zz = list(zip(array_phonemes, sent.split())) #  list(zip(graphs2phones(sent), sent.split()))\n",
    "#     # print(list(zz))\n",
    "#     return {ph: w for (ph, w) in list(zz)}\n",
    "#     # print(list(zz_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to avoid 'one sound for several words' effect, I break the words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tryout with Shelves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shelve \n",
    "\n",
    "def graphemes_to_phonemes_to_shelves(words_in_sent, shelf_filename):\n",
    "    \"\"\"\n",
    "        Takes a list of words and returns a list of tuples\n",
    "        (grapheme: phoneme)\n",
    "        Example:\n",
    "        > graphemes_to_phonemes([\"luis\", \"papa\"])\n",
    "        [('luis', \"lj'u:Iz\"), ('papa', \"pa#p'A:\")]\n",
    "    \"\"\"\n",
    "    MAX_LENGTH_TO_SPEAK = 10 # if I give more than this, espeak fails to do a good job \n",
    "    # First step: generate all sounds of words as if they were \"alone\" (ie, not in a sentence)\n",
    "    # We want to avoid a combination of words making only 1 sound\n",
    "    # For example (depending on accent): \"what's up?\"\n",
    "    # So in order to do that we'll introduce a word with a unique sound between the words, \n",
    "    # generate phonemes and then process them smartly: \n",
    "    # separator for words in sentence \n",
    "    separator = {\"str\": \"XXX\"}\n",
    "    separator[\"sound\"] = ''.join(graphs2phones(separator[\"str\"]))    \n",
    "    # \n",
    "    how_many_words = len(words_in_sent)\n",
    "    num_batches = (how_many_words // MAX_LENGTH_TO_SPEAK) + int(how_many_words % MAX_LENGTH_TO_SPEAK != 0)\n",
    "    result_dict = shelve.open(shelf_filename, flag='c')\n",
    "    try:\n",
    "        for i in range(num_batches):\n",
    "            logger.debug(\"{}: {} to {}\".format(i, i * MAX_LENGTH_TO_SPEAK, (i + 1)*MAX_LENGTH_TO_SPEAK))\n",
    "            words_in_batch = words_in_sent[i * MAX_LENGTH_TO_SPEAK: (i + 1)*MAX_LENGTH_TO_SPEAK]\n",
    "            logger.debug(\"words_in_batch = {}\".format(words_in_batch))\n",
    "            sent_augm = ' '.join([w1 + ' ' + w2 for w1, w2 in list(zip([separator[\"str\"]]*len(words_in_batch), words_in_batch))]) + \" \" + separator[\"str\"]\n",
    "            logger.debug(\"sent_augm = {}\".format(sent_augm))\n",
    "            phonemes_strs_augm = graphs2phones(sent_augm)\n",
    "            logger.debug(\"phonemes_strs_augm = {}\".format(phonemes_strs_augm))\n",
    "            # there we go: all (indexes of) sounds that we are interested in. \n",
    "            seps_idxs = [i for i,v in enumerate(phonemes_strs_augm) if v.endswith(separator[\"sound\"])]\n",
    "            logger.debug(\"seps_idxs = {}\".format(seps_idxs))\n",
    "            how_many_separators = len(seps_idxs)\n",
    "            logger.debug(\"how_many_separators = {}\".format(how_many_separators))\n",
    "\n",
    "            all_sounds = list(map(\n",
    "                lambda t: ' '.join(phonemes_strs_augm[t[0] + 1: t[1]]),\n",
    "                list(zip(seps_idxs[:-1], seps_idxs[1:]))))\n",
    "            logger.debug(\"all sounds = {}\".format(all_sounds))\n",
    "            result_for_batch = list(zip(words_in_batch, all_sounds))\n",
    "            for word, sound in result_for_batch:\n",
    "                result_dict[sound] = word \n",
    "            result_dict.sync()\n",
    "    finally:\n",
    "        logger.info(\"Closing shelf '{}'\".format(shelf_filename))\n",
    "        result_dict.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(mw.model.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alogger.setLevel(logging.DEBUG) # very verbose \n",
    "alogger.setLevel(logging.WARNING) # very quiet \n",
    "start = 0\n",
    "n = len(mw.model.index2word) - 1\n",
    "# (graphemes_and_phonemes, secs) = take_time(\"graphemes_to_phonemes(mw.model.index2word[{}:{}])\".format(start, start + n))\n",
    "# # (graphemes_and_phonemes, secs) = take_time(\"graphemes_to_phonemes(['New_York', 'luis', 'papa', 'New_York', 'luis'])\".format(start, start + n))\n",
    "# print(\"It took {} secs to generate {} phonemes strings\".format(secs, n))\n",
    "# # print(graphemes_and_phonemes)\n",
    "shelf_filename = \"shelf_from{}_for{}.shelf\".format(start, n)\n",
    "(_, secs) = take_time(\"graphemes_to_phonemes_to_shelves(mw.model.index2word[{}:{}], '{}')\".format(start, start + n, shelf_filename))\n",
    "print(\"[dict] It took {} secs to generate {} phonemes strings\".format(secs, n))\n",
    "# print(as_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphemes_to_phonemes('\"hey angel  you duh sexy\"'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shelf_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shelf_filename = 'shelf_from0_for2999999.shelf'\n",
    "result_dict = shelve.open(shelf_filename, flag='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_list = list(result_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "key_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_dict[key_list[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_dict.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END TRYOUT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graphemes_to_phonemes([\"luis\", \"papa\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d1 = {\"1\": \"uno\"}\n",
    "d2 = {\"111\": \"uno11\"}\n",
    "{**d1, **d2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 23\n",
    "s = list(range(n)) \n",
    "len(s) // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[20:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(\"{}: {} to {}\".format(i, i * 10, (i + 1)*10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alogger.setLevel(logging.DEBUG)\n",
    "import random\n",
    "import string \n",
    "def get_random_string(N: int) -> string: \n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=N))\n",
    "sss = ' '.join([\"XXX\", \"it\", \"XXX\", \"be\", \"XXX\", \"from\", \"XXX\", \"by\", \"XXX\", \"are\", \"XXX\", \"I\", \"XXX\", \"have\", \"XXX\", \"he\", \"XXX\", \"will\", \"XXX\", \"has\", \"XXX\", \"####\", \"XXX\", \"his\", \"XXX\", \"an\", \"XXX\", \"this\", \"XXX\", \"or\", \"XXX\", \"their\", \"XXX\", \"who\", \"XXX\", \"they\", \"XXX\", \"but\", \"XXX\", \"$\"])\n",
    "sss = ' '.join([get_random_string(N = 5)] * 30)\n",
    "sss = ' '.join([\"|\", \"it\", \"|\", \"be\", \"|\", \"from\", \"|\", \"by\", \"|\", \"are\", \"|\", \"I\", \"|\", \"have\", \"|\", \"he\", \"|\", \"will\", \"|\", \"has\", \"|\", \"####\", \"|\", \"his\", \"|\", \"an\", \"|\", \"this\", \"|\", \"or\", \"|\", \"their\", \"|\", \"who\", \"|\", \"they\", \"|\", \"but\", \"|\", \"$\"])\n",
    "print(sss)\n",
    "phons = graphs2phones(sss)\n",
    "print(phons)\n",
    "print(\"len of orig sentence: strings = {}, chars = {}\\nlen of sounds = {}\".format(len(sss.split()), len(sss), len(phons)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sss = ' '.join([\"it\", \"be\", \"from\", \"by\", \"are\", \"I\", \"have\", \"he\", \"will\", \"has\", \"####\", \"his\", \"an\", \"this\", \"or\", \"their\", \"who\", \"they\", \"but\", \"$\"])\n",
    "print(sss)\n",
    "phons = graphs2phones(sss)\n",
    "print(phons)\n",
    "print(\"len of orig sentence: strings = {}, chars = {}\\nlen of sounds = {}\".format(len(sss.split()), len(sss), len(phons)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# alogger.setLevel(logging.DEBUG) # very verbose \n",
    "alogger.setLevel(logging.WARNING) # very quiet \n",
    "start = 55\n",
    "n = 3000\n",
    "# (graphemes_and_phonemes, secs) = take_time(\"graphemes_to_phonemes(mw.model.index2word[{}:{}])\".format(start, start + n))\n",
    "# # (graphemes_and_phonemes, secs) = take_time(\"graphemes_to_phonemes(['New_York', 'luis', 'papa', 'New_York', 'luis'])\".format(start, start + n))\n",
    "# print(\"It took {} secs to generate {} phonemes strings\".format(secs, n))\n",
    "# # print(graphemes_and_phonemes)\n",
    "(as_dict, secs) = take_time(\"dict_phonemes_to_graphemes(mw.model.index2word[{}:{}])\".format(start, start + n))\n",
    "print(\"[dict] It took {} secs to generate {} phonemes strings\".format(secs, n))\n",
    "# print(as_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(mw.model.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "as_dict = dict_phonemes_to_graphemes(mw.model.index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_dict_to(the_dict, dict_file_name):\n",
    "    with open(dict_file_name, 'wb') as f:\n",
    "        pickle.dump(the_dict, f)\n",
    "\n",
    "def load_dict_from(dict_file_name) -> dict:\n",
    "    with open(dict_file_name, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f_name = \"blabla.pickle\"\n",
    "save_dict_to(as_dict, dict_file_name = f_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "as_dict_2 = load_dict_from(dict_file_name = f_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "as_dict == as_dict_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for w in mw.model.index2word[0:300]:\n",
    "    phs = graphs2phones(w)\n",
    "    if (len(phs) > 1):\n",
    "        print(\"'{}' => {} (length {})\".format(w, phs, len(phs)))\n",
    "    else:\n",
    "        if (len(phs) == 0):\n",
    "            print(\"'{}' has no phonemes\".format(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Migrate this "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from subprocess import check_output\n",
    "from timeit import default_timer as timer\n",
    "import functools\n",
    "import shelve\n",
    "\n",
    "\n",
    "class PhonemesFromGraphemes:\n",
    "\n",
    "    MAX_LENGTH_TO_SPEAK = 10  # if I give more than this, espeak fails to do a good job\n",
    "\n",
    "    def __init__(self, a_logger = None):\n",
    "        print(\"hello\")\n",
    "        if a_logger is None:\n",
    "            # create logger\n",
    "            self.alogger = logging.getLogger(__name__)\n",
    "            if not len(self.alogger.handlers):\n",
    "                self.alogger.setLevel(logging.DEBUG)\n",
    "\n",
    "                # create console handler and set level to debug\n",
    "                ch = logging.StreamHandler()\n",
    "                ch.setLevel(logging.DEBUG)\n",
    "\n",
    "                # create formatter\n",
    "                formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "                # add formatter to ch\n",
    "                ch.setFormatter(formatter)\n",
    "                # add ch to logger\n",
    "                self.alogger.addHandler(ch)\n",
    "            print(\"Logger created\")\n",
    "        else:\n",
    "            self.alogger = a_logger\n",
    "            print(\"Logger copied\")\n",
    "\n",
    "    def set_log_level(self, log_level):\n",
    "        \"\"\"\n",
    "            log_level: one of logging.{WARNING, ...} \n",
    "\n",
    "        \"\"\"\n",
    "        self.alogger.setLevel(log_level)\n",
    "\n",
    "    def graphs2phones(self, s):\n",
    "        \"\"\"\n",
    "            Graphemes to Phonemes: \n",
    "            Takes a sentence, returns an array of graphemes strings (one per number of words in original sentence)\n",
    "            Example(s): \n",
    "            > graphs2phones('hello world bla and ble')\n",
    "            > graphs2phones(' wasuuuppp!')\n",
    "        \"\"\"\n",
    "        phs = check_output([\"/usr/local/bin/speak\", \"-q\", \"-x\" ,'-v', 'en-us' ,s]).decode('utf-8')\n",
    "        self.alogger.debug(\"Return {} strings: {}\".format(len(phs.split()), phs))\n",
    "        return [w for w in phs.strip().split(\" \") if w != ' ']\n",
    "\n",
    "    def take_time(self, code_snippet_as_string):\n",
    "        \"\"\"\n",
    "            Measures the time it takes to execute the code snippet\n",
    "            provided as string. \n",
    "            Returns: the value of the invocation + number of seconds it took. \n",
    "            Example(s): \n",
    "            > r, secs = take_time(\"2 + 2\")\n",
    "            > print(\"result = {}, time = {} secs\".format(r, secs))\n",
    "        \"\"\"\n",
    "        start = timer()\n",
    "        r = eval(code_snippet_as_string)\n",
    "        end = timer()\n",
    "        return (r, end - start)\n",
    "\n",
    "    def graphemes_to_phonemes(self, words_in_sent):\n",
    "        \"\"\"\n",
    "            Takes a list of words and returns a list of tuples\n",
    "            (grapheme: phoneme)\n",
    "            Example:\n",
    "            > graphemes_to_phonemes([\"luis\", \"papa\"])\n",
    "            [('luis', \"lj'u:Iz\"), ('papa', \"pa#p'A:\")]\n",
    "        \"\"\"\n",
    "        # First step: generate all sounds of words as if they were \"alone\" (ie, not in a sentence)\n",
    "        # We want to avoid a combination of words making only 1 sound\n",
    "        # For example (depending on accent): \"what's up?\"\n",
    "        # So in order to do that we'll introduce a word with a unique sound between the words,\n",
    "        # generate phonemes and then process them smartly:\n",
    "        # separator for words in sentence\n",
    "        separator = {\"str\": \"XXX\"}\n",
    "        separator[\"sound\"] = ''.join(self.graphs2phones(separator[\"str\"]))\n",
    "        #\n",
    "        how_many_words = len(words_in_sent)\n",
    "        num_batches = (how_many_words // self.MAX_LENGTH_TO_SPEAK) + int(how_many_words % self.MAX_LENGTH_TO_SPEAK != 0)\n",
    "        result_array = [] # {}\n",
    "        for i in range(num_batches):\n",
    "            self.alogger.debug(\"{}: {} to {}\".format(i, i * self.MAX_LENGTH_TO_SPEAK, (i + 1 ) *self.MAX_LENGTH_TO_SPEAK))\n",
    "            words_in_batch = words_in_sent[i * self.MAX_LENGTH_TO_SPEAK: (i + 1 ) *self.MAX_LENGTH_TO_SPEAK]\n",
    "            self.alogger.debug(\"words_in_batch = {}\".format(words_in_batch))\n",
    "            sent_augm = ' '.join \\\n",
    "                ([w1 + ' ' + w2 for w1, w2 in list(zip([separator[\"str\"] ] *len(words_in_batch), words_in_batch))]) + \" \" + separator[\"str\"]\n",
    "            self.alogger.debug(\"sent_augm = {}\".format(sent_augm))\n",
    "            phonemes_strs_augm = self.graphs2phones(sent_augm)\n",
    "            self.alogger.debug(\"phonemes_strs_augm = {}\".format(phonemes_strs_augm))\n",
    "            # there we go: all (indexes of) sounds that we are interested in.\n",
    "            seps_idxs = [i for i ,v in enumerate(phonemes_strs_augm) if v.endswith(separator[\"sound\"])]\n",
    "            self.alogger.debug(\"seps_idxs = {}\".format(seps_idxs))\n",
    "            how_many_separators = len(seps_idxs)\n",
    "            self.alogger.debug(\"how_many_separators = {}\".format(how_many_separators))\n",
    "\n",
    "            all_sounds = list(map(\n",
    "                lambda t: ' '.join(phonemes_strs_augm[t[0] + 1: t[1]]),\n",
    "                list(zip(seps_idxs[:-1], seps_idxs[1:]))))\n",
    "            self.alogger.debug(\"all sounds = {}\".format(all_sounds))\n",
    "            result_array += list(zip(words_in_batch, all_sounds))\n",
    "        return result_array\n",
    "\n",
    "\n",
    "    def dict_graphemes_to_phonemes(self, words_in_sent) -> dict:\n",
    "        as_phon_graph_list = self.graphemes_to_phonemes(words_in_sent)\n",
    "        return {ph: graph for (graph, ph) in as_phon_graph_list}\n",
    "\n",
    "\n",
    "    def graphemes_to_phonemes_to_shelves(self, words_in_sent, shelf_filename):\n",
    "        \"\"\"\n",
    "            Takes a list of words and returns a list of tuples\n",
    "            (grapheme: phoneme)\n",
    "            Example:\n",
    "            > graphemes_to_phonemes([\"luis\", \"papa\"])\n",
    "            [('luis', \"lj'u:Iz\"), ('papa', \"pa#p'A:\")]\n",
    "        \"\"\"\n",
    "        # let's do this in batches:\n",
    "        how_many_words = len(words_in_sent)\n",
    "        num_batches = (how_many_words // self.MAX_LENGTH_TO_SPEAK) + int(how_many_words % self.MAX_LENGTH_TO_SPEAK != 0)\n",
    "        result_dict = shelve.open(shelf_filename, flag='c')\n",
    "        try:\n",
    "            for i in range(num_batches):\n",
    "                self.alogger.debug(\"batch {} out of {}: {} to {}\".format(i + 1, num_batches, i * self.MAX_LENGTH_TO_SPEAK, (i + 1)*self.MAX_LENGTH_TO_SPEAK))\n",
    "                words_in_batch = words_in_sent[i * self.MAX_LENGTH_TO_SPEAK: (i + 1)*self.MAX_LENGTH_TO_SPEAK]\n",
    "                result_for_batch = self.graphemes_to_phonemes(words_in_batch)\n",
    "                self.alogger.debug(\"[{}] result_for_batch = '{}'\".format(i, result_for_batch))\n",
    "                #\n",
    "                for word, sound in result_for_batch:\n",
    "                    ex_word = result_dict.get(sound)\n",
    "                    if ex_word is None:\n",
    "                        self.alogger.debug(\"For sound '{}' the dict is empty\".format(sound))\n",
    "                    else:\n",
    "                        self.alogger.debug(\"For sound '{}' the dict already has => {}\".format(sound, ex_word))\n",
    "                    print((ex_word if ex_word is not None else []) + [word])\n",
    "                    result_dict[sound] = (ex_word if ex_word is not None else []) + [word]\n",
    "                    self.alogger.debug(\"After inserting word '{}' => '{}' :: {}\".format(word, sound, result_dict[sound]))\n",
    "                result_dict.sync()\n",
    "        finally:\n",
    "            self.alogger.info(\"Closing shelf '{}'\".format(shelf_filename))\n",
    "            result_dict.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n",
      "Logger created\n"
     ]
    }
   ],
   "source": [
    "pg = PhonemesFromGraphemes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pg.alogger.handlers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-06-05 06:12:57,183 - __main__ - DEBUG - batch 1 out of 1: 0 to 10\n",
      "2017-06-05 06:12:57,198 - __main__ - DEBUG - Return 1 strings:  ,Eks,Eks'Eks\n",
      "\n",
      "2017-06-05 06:12:57,199 - __main__ - DEBUG - 0: 0 to 10\n",
      "2017-06-05 06:12:57,200 - __main__ - DEBUG - words_in_batch = ['you', 'you', 'you', '_You']\n",
      "2017-06-05 06:12:57,201 - __main__ - DEBUG - sent_augm = XXX you XXX you XXX you XXX _You XXX\n",
      "2017-06-05 06:12:57,220 - __main__ - DEBUG - Return 9 strings:  ,Eks,Eks'Eks ju: ,Eks,Eks'Eks ju: ,Eks,Eks'Eks ju: ,Eks,Eks'Eks ju: ,Eks,Eks'Eks\n",
      "\n",
      "2017-06-05 06:12:57,221 - __main__ - DEBUG - phonemes_strs_augm = [\",Eks,Eks'Eks\", 'ju:', \",Eks,Eks'Eks\", 'ju:', \",Eks,Eks'Eks\", 'ju:', \",Eks,Eks'Eks\", 'ju:', \",Eks,Eks'Eks\"]\n",
      "2017-06-05 06:12:57,222 - __main__ - DEBUG - seps_idxs = [0, 2, 4, 6, 8]\n",
      "2017-06-05 06:12:57,222 - __main__ - DEBUG - how_many_separators = 5\n",
      "2017-06-05 06:12:57,223 - __main__ - DEBUG - all sounds = ['ju:', 'ju:', 'ju:', 'ju:']\n",
      "2017-06-05 06:12:57,224 - __main__ - DEBUG - [0] result_for_batch = '[('you', 'ju:'), ('you', 'ju:'), ('you', 'ju:'), ('_You', 'ju:')]'\n",
      "2017-06-05 06:12:57,225 - __main__ - DEBUG - For sound 'ju:' the dict already has => ['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You']\n",
      "2017-06-05 06:12:57,225 - __main__ - DEBUG - After inserting word 'you' => 'ju:' :: ['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you']\n",
      "2017-06-05 06:12:57,226 - __main__ - DEBUG - For sound 'ju:' the dict already has => ['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you']\n",
      "2017-06-05 06:12:57,227 - __main__ - DEBUG - After inserting word 'you' => 'ju:' :: ['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you', 'you']\n",
      "2017-06-05 06:12:57,227 - __main__ - DEBUG - For sound 'ju:' the dict already has => ['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you', 'you']\n",
      "2017-06-05 06:12:57,228 - __main__ - DEBUG - After inserting word 'you' => 'ju:' :: ['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you', 'you', 'you']\n",
      "2017-06-05 06:12:57,229 - __main__ - DEBUG - For sound 'ju:' the dict already has => ['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you', 'you', 'you']\n",
      "2017-06-05 06:12:57,230 - __main__ - DEBUG - After inserting word '_You' => 'ju:' :: ['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you', 'you', 'you', '_You']\n",
      "2017-06-05 06:12:57,231 - __main__ - INFO - Closing shelf 'delete_this_shelf'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you']\n",
      "['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you', 'you']\n",
      "['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you', 'you', 'you']\n",
      "['you', 'you', 'you', '_You', 'you', 'you', 'you', '_You', 'you', 'you', 'you', '_You']\n"
     ]
    }
   ],
   "source": [
    "pg.graphemes_to_phonemes_to_shelves(words_in_sent = \"you you you _You\".split(), shelf_filename = \"delete_this_shelf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (python3.6)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
