{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extend Word2Vec Model with Phonemes \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Word2Vec model trained with 100B words\n",
    "\n",
    "\n",
    "from https://code.google.com/archive/p/word2vec/ \n",
    "### and wrap-it up in a ready-to-use class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = None # cache of Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def set_logging_as(a_level):\n",
    "    logger.setLevel(a_level)\n",
    "\n",
    "    # logging.basicConfig(format='%(asctime)s : %(levelname)s : %(module)s:%(lineno)d : %(funcName)s(%(threadName)s) : %(message)s')\n",
    "\n",
    "#     ,\n",
    "#         level=a_level)\n",
    "\n",
    "# initialization: \n",
    "set_logging_as(logging.DEBUG)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEBUG'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.getLevelName(logger.getEffectiveLevel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_logging_as(logging.DEBUG)\n",
    "logger.info(\"lalala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set_logging_as(logging.CRITICAL)\n",
    "logger.info(\"lalala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create logger\n",
    "alogger = logging.getLogger(__name__)\n",
    "alogger.setLevel(logging.DEBUG)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "\n",
    "# create formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "# add ch to logger\n",
    "alogger.addHandler(ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEBUG'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.getLevelName(alogger.getEffectiveLevel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alogger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-29 13:41:39,943 - __main__ - INFO - lala\n"
     ]
    }
   ],
   "source": [
    "alogger.info(\"lala\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim \n",
    "import bisect \n",
    "import numpy as np\n",
    "\n",
    "class ModelWrapper():\n",
    "    \n",
    "    def __init__(self, m):\n",
    "        if m is None:\n",
    "            print(\"Loading model...\")\n",
    "            self.model = gensim.models.word2vec.KeyedVectors.load_word2vec_format('{}/GoogleNews-vectors-negative300.bin.gz'.format(data_dir), binary=True)\n",
    "            print(\"Model succesfully loaded\")\n",
    "#             print(\"Cleaning up un-needed details from model...\")\n",
    "#             try:\n",
    "#                 del self.model.syn0  # not needed => free up mem\n",
    "#                 del self.model.syn1\n",
    "#             except:\n",
    "#                 pass\n",
    "        else:\n",
    "            print(\"[init] Model provided. If you want me to FORCE re-load it, call ModelWrapper's constructor with 'None'\")\n",
    "            self.model = m            \n",
    "        # sort all the words in the model, so that we can auto-complete queries quickly\n",
    "        print(\"Sort all the words in the model, so that we can auto-complete queries quickly...\")\n",
    "        self.orig_words = [gensim.utils.to_unicode(word) for word in self.model.index2word]\n",
    "        indices = [i for i, _ in sorted(enumerate(self.orig_words), key=lambda item: item[1].lower())]\n",
    "        self.all_words = [self.orig_words[i].lower() for i in indices]  # lowercased, sorted as lowercased\n",
    "        self.orig_words = [self.orig_words[i] for i in indices]  # original letter casing, but sorted as if lowercased            \n",
    "        \n",
    "    def suggest(self, term):\n",
    "        \"\"\"\n",
    "        For a given prefix, return 10 words that exist in the model start start with that prefix\n",
    "        \"\"\"\n",
    "        prefix = gensim.utils.to_unicode(term).strip().lower()\n",
    "        count = 10\n",
    "        pos = bisect.bisect_left(self.all_words, prefix)\n",
    "        result = self.orig_words[pos: pos + count]\n",
    "        logger.info(\"suggested %r: %s\" % (prefix, result))\n",
    "        return result      \n",
    "    \n",
    "    def most_similar(self, positive, negative):\n",
    "        \"\"\"\n",
    "            positive: an array of positive words\n",
    "            negative: an array of negative words \n",
    "        \"\"\"                \n",
    "        try:\n",
    "            result = self.model.most_similar(\n",
    "                positive=[word.strip() for word in positive if word],\n",
    "                negative=[word.strip() for word in negative if word],\n",
    "                topn=5)\n",
    "        except:\n",
    "            result = []\n",
    "        logger.info(\"similars for %s vs. %s: %s\" % (positive, negative, result))\n",
    "        return {'similars': result}    \n",
    "    \n",
    "    def vec_repr(self, word):\n",
    "        \"\"\"\n",
    "            If 'word' belongs in the vocabulary, returns its \n",
    "            word2vec representation. Otherwise returns a vector of 0's\n",
    "            of the same length of the other words. \n",
    "        \"\"\"\n",
    "        try:\n",
    "            return self.model.word_vec(word)\n",
    "        except KeyError:\n",
    "            logger.debug(\"'{}' not in Model. Returning [0]'s vector.\".format(word))\n",
    "            return np.zeros(self.model.vector_size)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n",
      "Model succesfully loaded\n",
      "Sort all the words in the model, so that we can auto-complete queries quickly...\n"
     ]
    }
   ],
   "source": [
    "mw = ModelWrapper(model)\n",
    "model = mw.model # just cache in case I re-call this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000000, 300)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw.model.syn0.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(mw.model.vocab.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The', 'with', 'said']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# my_dictionary = {k: f(v) for k, v in my_dictionary.items()}\n",
    "mw.model.index2word[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8745957211429348"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.uniform(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "phonemes_words = [(graphs2phones(w),w) for w in mw.model.index2word[:100]]\n",
    "phonemes_dict = {ph[0]:w for ph, w in phonemes_words if len(ph) == 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_phonemes_dict(from_idx, how_many_words):\n",
    "    sent = ' '.join(mw.model.index2word[from_idx:from_idx + how_many_words])\n",
    "    print(sent)\n",
    "    array_phonemes =  graphs2phones(sent)\n",
    "    print(array_phonemes)\n",
    "    assert len(array_phonemes) == how_many_words, \"(Have {} phoneme-strings, {} words) Looks like some words in vocab have phonemes-strings > 1\".format(len(array_phonemes), how_many_words)\n",
    "    zz = list(zip(array_phonemes, sent.split())) #  list(zip(graphs2phones(sent), sent.split()))\n",
    "    # print(list(zz))\n",
    "    return {ph: w for (ph, w) in list(zz)}\n",
    "    # print(list(zz_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that is on ## The\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from_idx = 3; how_many_words = 5\n",
    "sent = ' '.join(mw.model.index2word[from_idx:from_idx + how_many_words])\n",
    "print(sent)\n",
    "len(sent.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[' ']*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'</s>' => [\"sl'aS\", \"_:_:'Es\"] (length 2)\n",
      "'##th' => [\"h'aShaS\", \"t,i:;'eItS\"] (length 2)\n"
     ]
    }
   ],
   "source": [
    "for w in mw.model.index2word[0:300]:\n",
    "    phs = graphs2phones(w)\n",
    "    if (len(phs) > 1):\n",
    "        print(\"'{}' => {} (length {})\".format(w, phs, len(phs)))\n",
    "    else:\n",
    "        if (len(phs) == 0):\n",
    "            print(\"'{}' has no phonemes\".format(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'luis'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'luis\\n'[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The']"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw.model.index2word[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In order to avoid 'one sound for several words' effect, I break the words: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XXX </s> XXX in XXX for XXX that XXX is XXX on XXX ## XXX The XXX\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[\",Eks,Eks'Eks\",\n",
       " \"sl'aS\",\n",
       " \"_:_:'Es\",\n",
       " \"_:_:,Eks,Eks'Eks\",\n",
       " 'In',\n",
       " \",Eks,Eks'Eks\",\n",
       " 'fO@r',\n",
       " \",Eks,Eks'Eks\",\n",
       " 'Dat',\n",
       " \",Eks,Eks'Eks\",\n",
       " 'Iz',\n",
       " \",Eks,Eks'Eks\",\n",
       " ',0n',\n",
       " \",Eks,Eks'Eks\",\n",
       " \"h'aShaS\",\n",
       " \",Eks,Eks'Eks\",\n",
       " 'DI2;',\n",
       " \",Eks,Eks'Eks\"]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_sent = mw.model.index2word[0:8]\n",
    "sent_augm = ' '.join([w1 + ' ' + w2 for w1, w2 in list(zip(['XXX']*len(words_in_sent), words_in_sent))]) + ' XXX'\n",
    "print(sent_augm)\n",
    "phonemes_strs_augm = graphs2phones(sent_augm)\n",
    "phonemes_strs_augm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's generate all sounds, and keep the ones that are NOT 'separator: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 6, 8, 10, 12, 14, 16]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xxx_sound = ''.join(graphs2phones('XXX'))\n",
    "# xxx_sound\n",
    "idxs_phonemes_strs = [i for i,v in enumerate(phonemes_strs_augm) if not v.endswith(xxx_sound)]\n",
    "idxs_phonemes_strs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### let's now detect the sounds that came from same word (ie, contiguous sounds): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def do_process(idxs):    \n",
    "    if len(idxs) == 0:\n",
    "        r = []\n",
    "    else:\n",
    "        if len(idxs) == 1:\n",
    "            r = [idxs]\n",
    "        else:\n",
    "            if idxs[0] + 1 == idxs[1]:\n",
    "                r = [[idxs[0], idxs[1]]] + do_process(idxs[2:])\n",
    "            else:\n",
    "                r = [[idxs[0]]] + do_process(idxs[1:])\n",
    "    return r \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [4], [6], [8], [10], [12], [14], [16]]"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_process(idxs_phonemes_strs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('</s>', \"sl'aS _:_:'Es\"),\n",
       " ('in', 'In'),\n",
       " ('for', 'fO@r'),\n",
       " ('that', 'Dat'),\n",
       " ('is', 'Iz'),\n",
       " ('on', ',0n'),\n",
       " ('##', \"h'aShaS\"),\n",
       " ('The', 'DI2;')]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(words_in_sent[int(i[0]/2 - 1)], phonemes_strs_augm[i[0]]) if len(i) == 1 else (words_in_sent[int(i[1]/2 - 1)], ' '.join(phonemes_strs_augm[i[0]:i[1] + 1])) for i in do_process(idxs_phonemes_strs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4, 6, 8, 10, 12, 14, 16]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_phonemes_strs\n",
    "# idxs = [i[0] for i in do_process(idxs_phonemes_strs) if len(i) == 1]\n",
    "idxs = [i[0] if len(i) == 1 else i[1] for i in do_process(idxs_phonemes_strs)]\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>', 'in', 'for', 'that', 'is', 'on', '##', 'The']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_in_sent[int(16/2 - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('in', 'In'),\n",
       " ('for', 'fO@r'),\n",
       " ('that', 'Dat'),\n",
       " ('is', 'Iz'),\n",
       " ('on', ',0n'),\n",
       " ('##', \"h'aShaS\"),\n",
       " ('The', 'DI2;')]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(words_in_sent[int(i/2 - 1)], phonemes_strs_augm[i]) for i in idxs] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<string>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    1:2\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "rr[eval('1:2')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s> in for that is on ## The with said was the at not as\n",
      "[\"sl'aS\", \"_:_:'Es\", '_:_:In', 'fO@', 'Dat', 'Iz', ',0n', \"h'aShaS\", 'D@2', 'wID', \"s'Ed\", 'w0zDI2;', 'at', 'n,0t', 'az']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.029420072998618707"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(phonemes_dict_1, tInSecs_1) = take_time(\"build_phonemes_dict(0, 15)\")\n",
    "tInSecs_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.924127916994621"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tInSecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"w'0s@,VVp\"]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs2phones(' wasuuuppp!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(phonemes_dict, tInSecs) = take_time(\"{''.join(graphs2phones(w)): w for w in mw.model.index2word[1:300]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9037140449945582"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tInSecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"s@l'Vt\", \"k'A:\", \"v'A:\", \"baI'En\"]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs2phones('salut ca va bien')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "def take_time(f):\n",
    "    start = timer()\n",
    "    r = eval(f)\n",
    "    end = timer()\n",
    "    return (r, end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphemes 2 Phonemes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"h@l'oU\", \"w'3:ld\", \"bl'A:\", '_:_:and', \"bl'i:\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from subprocess import check_output\n",
    "def graphs2phones(s): \n",
    "    \"\"\"\n",
    "        Takes a sentences, returns an array of graphemes strings (one per number of words in original sentence)\n",
    "    \"\"\"\n",
    "    phs = check_output([\"speak\", \"-q\", \"-x\",'-v', 'en-us',s]).decode('utf-8')\n",
    "    return [w for w in phs.strip().split(\" \") if w != ' ']\n",
    "\n",
    "# example: \n",
    "graphs2phones('hello world bla and ble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"f'Vkk\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphs2phones('fuckk fuck fuc fuk')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-29 13:50:19,665 - __main__ - INFO - similars for ['soccer'] vs. ['messi']: [('Soccer', 0.48688480257987976), ('lacrosse', 0.4622202515602112), ('softball', 0.4572678506374359), ('Lacrosse', 0.4419728219509125), ('basketball', 0.4305872321128845)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'similars': [('Soccer', 0.48688480257987976),\n",
       "  ('lacrosse', 0.4622202515602112),\n",
       "  ('softball', 0.4572678506374359),\n",
       "  ('Lacrosse', 0.4419728219509125),\n",
       "  ('basketball', 0.4305872321128845)]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mw.most_similar(positive = ['soccer'], negative = ['messi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's sanity check the Word2Vec model we just wrapped up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-05-29 13:50:21,973 - __main__ - DEBUG - 'piripiri' not in Model. Returning [0]'s vector.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check: all good, 'piripiri' was assigned the empty vector as representation\n"
     ]
    }
   ],
   "source": [
    "assert np.count_nonzero(mw.vec_repr('piripiri')) == 0, \"'piripiri' is present in this model???\"\n",
    "print(\"Sanity check: all good, 'piripiri' was assigned the empty vector as representation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check: all good, 'dog' has a meaningful representation\n"
     ]
    }
   ],
   "source": [
    "assert np.count_nonzero(mw.vec_repr('dog')) > 0, \"'dog' is not present in this model???\"\n",
    "print(\"Sanity check: all good, 'dog' has a meaningful representation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (python3.6)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
